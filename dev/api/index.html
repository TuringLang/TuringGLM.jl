<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>API reference · TuringGLM.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link rel="canonical" href="https://TuringLang.github.io/TuringGLM.jl/api/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="TuringGLM.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">TuringGLM.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../tutorials/linear_regression/">Linear Regression</a></li><li><a class="tocitem" href="../tutorials/logistic_regression/">Logistic Regression</a></li><li><a class="tocitem" href="../tutorials/poisson_regression/">Poisson Regression</a></li><li><a class="tocitem" href="../tutorials/negative_binomial_regression/">Negative Binomial Regression</a></li><li><a class="tocitem" href="../tutorials/robust_regression/">Robust Regression</a></li><li><a class="tocitem" href="../tutorials/hierarchical_models/">Hierarchical Models</a></li><li><a class="tocitem" href="../tutorials/custom_priors/">Custom Priors</a></li></ul></li><li class="is-active"><a class="tocitem" href>API reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>API reference</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>API reference</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/TuringLang/TuringGLM.jl/blob/master/docs/src/api.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="TuringGLM"><a class="docs-heading-anchor" href="#TuringGLM">TuringGLM</a><a id="TuringGLM-1"></a><a class="docs-heading-anchor-permalink" href="#TuringGLM" title="Permalink"></a></h1><p>Documentation for <a href="https://github.com/TuringLang/TuringGLM.jl">TuringGLM</a>.</p><ul><li><a href="#TuringGLM.CustomPrior"><code>TuringGLM.CustomPrior</code></a></li><li><a href="#TuringGLM.NegativeBinomial2-Union{Tuple{T}, Tuple{T, T}} where T&lt;:Real"><code>TuringGLM.NegativeBinomial2</code></a></li><li><a href="#TuringGLM.center_predictors-Tuple{AbstractMatrix{T} where T}"><code>TuringGLM.center_predictors</code></a></li><li><a href="#TuringGLM.convert_str_to_indices-Tuple{AbstractVector{T} where T}"><code>TuringGLM.convert_str_to_indices</code></a></li><li><a href="#TuringGLM.data_fixed_effects-Union{Tuple{D}, Tuple{StatsModels.FormulaTerm, D}} where D"><code>TuringGLM.data_fixed_effects</code></a></li><li><a href="#TuringGLM.data_random_effects-Union{Tuple{D}, Tuple{StatsModels.FormulaTerm, D}} where D"><code>TuringGLM.data_random_effects</code></a></li><li><a href="#TuringGLM.data_response-Union{Tuple{D}, Tuple{StatsModels.FormulaTerm, D}} where D"><code>TuringGLM.data_response</code></a></li><li><a href="#TuringGLM.get_idx-Union{Tuple{D}, Tuple{StatsModels.Term, D}} where D"><code>TuringGLM.get_idx</code></a></li><li><a href="#TuringGLM.get_var-Union{Tuple{D}, Tuple{StatsModels.Term, D}} where D"><code>TuringGLM.get_var</code></a></li><li><a href="#TuringGLM.has_ranef-Tuple{StatsModels.FormulaTerm}"><code>TuringGLM.has_ranef</code></a></li><li><a href="#TuringGLM.intercept_per_ranef-Tuple{Tuple}"><code>TuringGLM.intercept_per_ranef</code></a></li><li><a href="#TuringGLM.n_ranef-Tuple{StatsModels.FormulaTerm}"><code>TuringGLM.n_ranef</code></a></li><li><a href="#TuringGLM.ranef-Tuple{StatsModels.FormulaTerm}"><code>TuringGLM.ranef</code></a></li><li><a href="#TuringGLM.slope_per_ranef-Tuple{Tuple}"><code>TuringGLM.slope_per_ranef</code></a></li><li><a href="#TuringGLM.standardize_predictors-Tuple{AbstractMatrix{T} where T}"><code>TuringGLM.standardize_predictors</code></a></li><li><a href="#TuringGLM.standardize_predictors-Tuple{AbstractVector{T} where T}"><code>TuringGLM.standardize_predictors</code></a></li><li><a href="#TuringGLM.tuple_length-Union{Tuple{Tuple{Vararg{Any, N}}}, Tuple{N}} where N"><code>TuringGLM.tuple_length</code></a></li><li><a href="#TuringGLM.turing_model-Union{Tuple{D}, Tuple{StatsModels.FormulaTerm, D}} where D"><code>TuringGLM.turing_model</code></a></li></ul><article class="docstring"><header><a class="docstring-binding" id="TuringGLM.CustomPrior" href="#TuringGLM.CustomPrior"><code>TuringGLM.CustomPrior</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CustomPrior(predictors, intercept, auxiliary)</code></pre><p>struct to hold information regarding user-specified custom priors.</p><p><strong>Usage</strong></p><p>The <code>CustomPrior</code> struct has 3 fields:</p><ol><li><code>predictors</code>: the β coefficients.</li><li><code>intercept</code>: the α intercept.</li><li><code>auxiliary</code>: an auxiliary parameter.</li></ol><p>In robust models, e.g. Linear Regression with Student-t likelihood or Count Regression with Negative Binomial likelihood, often there is an extra auxiliary parameter that is needed to parametrize to model to overcome under- or over-dispersion. If you are specifying a custom prior for one of these type of models, then you should also specify a prior for the auxiliary parameter.</p><p>Non-robust models do not need an auxiliary parameter and you can pass <code>nothing</code> as the auxiliary argument.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/TuringGLM.jl/blob/7ead39d2795dab9e01b8c2881783c4228ae25ec5/src/priors.jl#L5-L26">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TuringGLM.NegativeBinomial2-Union{Tuple{T}, Tuple{T, T}} where T&lt;:Real" href="#TuringGLM.NegativeBinomial2-Union{Tuple{T}, Tuple{T, T}} where T&lt;:Real"><code>TuringGLM.NegativeBinomial2</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">NegativeBinomial2(μ, ϕ)</code></pre><p>An alternative parameterization of the Negative Binomial distribution:</p><p class="math-container">\[\text{Negative-Binomial}(n \mid \mu, \phi) \sim \binom{n + \phi - 1}{n} \left( \frac{\mu}{\mu + \phi} \right)^{n!} \left( \frac{\phi}{\mu + \phi} \right)^{\phi!}\]</p><p>where the expectation is μ and variance is (μ + μ²/ϕ).</p><p>The alternative parameterization is inspired by the <a href="https://mc-stan.org/docs/functions-reference/nbalt.html">Stan&#39;s <code>neg_binomial_2</code> function</a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/TuringGLM.jl/blob/7ead39d2795dab9e01b8c2881783c4228ae25ec5/src/turing_model.jl#L551-L563">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TuringGLM.center_predictors-Tuple{AbstractMatrix{T} where T}" href="#TuringGLM.center_predictors-Tuple{AbstractMatrix{T} where T}"><code>TuringGLM.center_predictors</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">center_predictors(X::AbstractMatrix)</code></pre><p>Centers the columns of a matrix <code>X</code> of predictors to mean 0.</p><p>Returns a tuple with:</p><ol><li><code>μ_X</code>: 1xK <code>Matrix</code> of <code>Float64</code>s of the means of the K columns in the original <code>X</code></li></ol><p>matrix.</p><ol><li><code>X_centered</code>: A <code>Matrix</code> of <code>Float64</code>s with the same dimensions as the original matrix</li></ol><p><code>X</code> with the columns centered on mean μ=0.</p><p><strong>Arguments</strong></p><ul><li><code>X::AbstractMatrix</code>: a matrix of predictors where rows are observations and columns are</li></ul><p>variables.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/TuringGLM.jl/blob/7ead39d2795dab9e01b8c2881783c4228ae25ec5/src/utils.jl#L1-L15">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TuringGLM.convert_str_to_indices-Tuple{AbstractVector{T} where T}" href="#TuringGLM.convert_str_to_indices-Tuple{AbstractVector{T} where T}"><code>TuringGLM.convert_str_to_indices</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">convert_str_to_indices(v::AbstractVector)</code></pre><p>Converts a vector <code>v</code> to a vector of indices, i.e. a vector where all the entries are integers. Returns a tuple with the first element as the converted vector and the second element a <code>Dict</code> specifying which string is which integer.</p><p>This function is especially useful for random-effects varying-intercept hierarchical models. Normally <code>v</code> would be a vector of group membership with values such as <code>&quot;group_1&quot;</code>, <code>&quot;group_2&quot;</code> etc. For random-effect models with varying-intercepts, Turing needs the group membership values to be passed as <code>Int</code>s.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/TuringGLM.jl/blob/7ead39d2795dab9e01b8c2881783c4228ae25ec5/src/utils.jl#L80-L91">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TuringGLM.data_fixed_effects-Union{Tuple{D}, Tuple{StatsModels.FormulaTerm, D}} where D" href="#TuringGLM.data_fixed_effects-Union{Tuple{D}, Tuple{StatsModels.FormulaTerm, D}} where D"><code>TuringGLM.data_fixed_effects</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">data_fixed_effects(formula::FormulaTerm, data)</code></pre><p>Constructs the matrix X of fixed-effects (a.k.a. population-level) predictors.</p><p>Returns a <code>Matrix</code> of the fixed-effects predictors variables in the <code>formula</code> and present inside <code>data</code>.</p><p><strong>Arguments</strong></p><ul><li><code>formula</code>: a <code>FormulaTerm</code> created by <code>@formula</code> macro.</li><li><code>data</code>:  a <code>data</code> object that satisfies the</li></ul><p><a href="https://github.com/JuliaData/Tables.jl">Tables.jl</a> interface such as a DataFrame.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/TuringGLM.jl/blob/7ead39d2795dab9e01b8c2881783c4228ae25ec5/src/data_constructors.jl#L27-L39">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TuringGLM.data_random_effects-Union{Tuple{D}, Tuple{StatsModels.FormulaTerm, D}} where D" href="#TuringGLM.data_random_effects-Union{Tuple{D}, Tuple{StatsModels.FormulaTerm, D}} where D"><code>TuringGLM.data_random_effects</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">data_random_effects(formula::FormulaTerm, data)</code></pre><p>Constructs the vector(s)/matrix(ces) Z(s) of random-effects (a.k.a. group-level) slope predictors.</p><p>Returns a <code>Dict{String, AbstractArray}</code> of <code>Vector</code>/<code>Matrix</code> as values of the random-effects predictors slope variables (keys) in the <code>formula</code> and present inside <code>data</code>.</p><p><strong>Arguments</strong></p><ul><li><code>formula</code>: a <code>FormulaTerm</code> created by <code>@formula</code> macro.</li><li><code>data</code>:  a <code>data</code> object that satisfies the</li></ul><p><a href="https://github.com/JuliaData/Tables.jl">Tables.jl</a> interface such as a DataFrame.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/TuringGLM.jl/blob/7ead39d2795dab9e01b8c2881783c4228ae25ec5/src/data_constructors.jl#L53-L66">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TuringGLM.data_response-Union{Tuple{D}, Tuple{StatsModels.FormulaTerm, D}} where D" href="#TuringGLM.data_response-Union{Tuple{D}, Tuple{StatsModels.FormulaTerm, D}} where D"><code>TuringGLM.data_response</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">data_response(formula::FormulaTerm, data)</code></pre><p>Constructs the response y vector.</p><p>Returns a <code>Vector</code> of the response variable in the <code>formula</code> and present inside <code>data</code>.</p><p><strong>Arguments</strong></p><ul><li><code>formula</code>: a <code>FormulaTerm</code> created by <code>@formula</code> macro.</li><li><code>data</code>:  a <code>data</code> object that satisfies the</li></ul><p><a href="https://github.com/JuliaData/Tables.jl">Tables.jl</a> interface such as a DataFrame.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/TuringGLM.jl/blob/7ead39d2795dab9e01b8c2881783c4228ae25ec5/src/data_constructors.jl#L11-L21">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TuringGLM.get_idx-Union{Tuple{D}, Tuple{StatsModels.Term, D}} where D" href="#TuringGLM.get_idx-Union{Tuple{D}, Tuple{StatsModels.Term, D}} where D"><code>TuringGLM.get_idx</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">get_idx(term::Term, data)</code></pre><p>Returns a tuple with the first element as the ID vector of <code>Int</code>s that represent group membership for a specific random-effect intercept group <code>t</code> of observations present in <code>data</code>. The second element of the tuple is a <code>Dict</code> specifying which string is which integer in the ID vector.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/TuringGLM.jl/blob/7ead39d2795dab9e01b8c2881783c4228ae25ec5/src/data_constructors.jl#L190-L197">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TuringGLM.get_var-Union{Tuple{D}, Tuple{StatsModels.Term, D}} where D" href="#TuringGLM.get_var-Union{Tuple{D}, Tuple{StatsModels.Term, D}} where D"><code>TuringGLM.get_var</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">get_var(term::Term, data)</code></pre><p>Returns the corresponding vector of column in <code>data</code> for the a specific random-effect slope <code>term</code> of observations present in <code>data</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/TuringGLM.jl/blob/7ead39d2795dab9e01b8c2881783c4228ae25ec5/src/data_constructors.jl#L204-L209">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TuringGLM.has_ranef-Tuple{StatsModels.FormulaTerm}" href="#TuringGLM.has_ranef-Tuple{StatsModels.FormulaTerm}"><code>TuringGLM.has_ranef</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">has_ranef(formula::FormulaTerm)</code></pre><p>Returns <code>true</code> if any of the terms in <code>formula</code> is a <code>FunctionTerm</code> or false otherwise.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/TuringGLM.jl/blob/7ead39d2795dab9e01b8c2881783c4228ae25ec5/src/data_constructors.jl#L93-L98">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TuringGLM.intercept_per_ranef-Tuple{Tuple}" href="#TuringGLM.intercept_per_ranef-Tuple{Tuple}"><code>TuringGLM.intercept_per_ranef</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">intercept_per_ranef(terms::Tuple{RandomEffectsTerm})</code></pre><p>Returns a vector of <code>String</code>s where the entries are the grouping variables that have a group-level intercept.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/TuringGLM.jl/blob/7ead39d2795dab9e01b8c2881783c4228ae25ec5/src/data_constructors.jl#L147-L152">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TuringGLM.n_ranef-Tuple{StatsModels.FormulaTerm}" href="#TuringGLM.n_ranef-Tuple{StatsModels.FormulaTerm}"><code>TuringGLM.n_ranef</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">n_ranef(formula::FormulaTerm)</code></pre><p>Returns the number of <code>RandomEffectsTerm</code>s in <code>formula</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/TuringGLM.jl/blob/7ead39d2795dab9e01b8c2881783c4228ae25ec5/src/data_constructors.jl#L122-L126">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TuringGLM.ranef-Tuple{StatsModels.FormulaTerm}" href="#TuringGLM.ranef-Tuple{StatsModels.FormulaTerm}"><code>TuringGLM.ranef</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">ranef(formula::FormulaTerm)</code></pre><p>Returns a tuple of the <code>FunctionTerm</code>s parsed as <code>RandomEffectsTerm</code>s in <code>formula</code>. If there are no <code>FunctionTerm</code>s in <code>formula</code> returns <code>nothing</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/TuringGLM.jl/blob/7ead39d2795dab9e01b8c2881783c4228ae25ec5/src/data_constructors.jl#L103-L108">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TuringGLM.slope_per_ranef-Tuple{Tuple}" href="#TuringGLM.slope_per_ranef-Tuple{Tuple}"><code>TuringGLM.slope_per_ranef</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">slope_per_ranef(terms::Tuple{RandomEffectsTerm})</code></pre><p>Returns a <code>SlopePerRanEf</code> object where the entries are the grouping variables that have a group-level slope.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/TuringGLM.jl/blob/7ead39d2795dab9e01b8c2881783c4228ae25ec5/src/data_constructors.jl#L165-L170">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TuringGLM.standardize_predictors-Tuple{AbstractMatrix{T} where T}" href="#TuringGLM.standardize_predictors-Tuple{AbstractMatrix{T} where T}"><code>TuringGLM.standardize_predictors</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">standardize_predictors(X::AbstractMatrix)</code></pre><p>Standardizes the columns of a matrix <code>X</code> of predictors to mean 0 and standard deviation 1.</p><p>Returns a tuple with:</p><ol><li><code>μ_X</code>: 1xK <code>Matrix</code> of <code>Float64</code>s of the means of the K columns in the original <code>X</code></li></ol><p>matrix.</p><ol><li><code>σ_X</code>: 1xK <code>Matrix</code> of <code>Float64</code>s of the standard deviations of the K columns in the</li></ol><p>original <code>X</code> matrix.</p><ol><li><code>X_std</code>: A <code>Matrix</code> of <code>Float64</code>s with the same dimensions as the original matrix</li></ol><p><code>X</code> with the columns centered on mean μ=0 and standard deviation σ=1.</p><p><strong>Arguments</strong></p><ul><li><code>X::AbstractMatrix</code>: a matrix of predictors where rows are observations and columns are</li></ul><p>variables.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/TuringGLM.jl/blob/7ead39d2795dab9e01b8c2881783c4228ae25ec5/src/utils.jl#L25-L41">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TuringGLM.standardize_predictors-Tuple{AbstractVector{T} where T}" href="#TuringGLM.standardize_predictors-Tuple{AbstractVector{T} where T}"><code>TuringGLM.standardize_predictors</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">standardize_predictors(x::AbstractVector)</code></pre><p>Standardizes the vector <code>x</code> to mean 0 and standard deviation 1.</p><p>Returns a tuple with:</p><ol><li><code>μ_X</code>: <code>Float64</code>s of the mean of the original vector <code>x</code>.</li><li><code>σ_X</code>: <code>Float64</code>s of the standard deviations of the original vector <code>x</code>.</li><li><code>x_std</code>: A <code>Vector</code> of <code>Float64</code>s with the same length as the original vector</li></ol><p><code>x</code> with the values centered on mean μ=0 and standard deviation σ=1.</p><p><strong>Arguments</strong></p><ul><li><code>x::AbstractVector</code>: a vector.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/TuringGLM.jl/blob/7ead39d2795dab9e01b8c2881783c4228ae25ec5/src/utils.jl#L52-L65">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TuringGLM.tuple_length-Union{Tuple{Tuple{Vararg{Any, N}}}, Tuple{N}} where N" href="#TuringGLM.tuple_length-Union{Tuple{Tuple{Vararg{Any, N}}}, Tuple{N}} where N"><code>TuringGLM.tuple_length</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">tuple_length(::NTuple{N, Any}) where {N} = Int(N)</code></pre><p>This is a hack to get the length of any tuple.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/TuringGLM.jl/blob/7ead39d2795dab9e01b8c2881783c4228ae25ec5/src/utils.jl#L73-L77">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TuringGLM.turing_model-Union{Tuple{D}, Tuple{StatsModels.FormulaTerm, D}} where D" href="#TuringGLM.turing_model-Union{Tuple{D}, Tuple{StatsModels.FormulaTerm, D}} where D"><code>TuringGLM.turing_model</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">turing_model(formula, data; model=Gaussian(), priors=DefaultPrior(), standardize=false)
turing_model(formula, data, model; priors=DefaultPrior(), standardize=false)</code></pre><p>Create a Turing model using <code>formula</code> syntax and a <code>data</code> source.</p><p><strong><code>formula</code></strong></p><p><code>formula</code> is the the same friendly interface to specify used to specify statistical models by <a href="https://paul-buerkner.github.io/brms/"><code>brms</code></a>, <a href="https://mc-stan.org/rstanarm/index.html"><code>rstarnarm</code></a>, <a href="https://bambinos.github.io/bambi"><code>bambi</code></a>, <a href="https://juliastats.org/StatsModels.jl/latest/"><code>StatsModels.jl</code></a> and <a href="https://juliastats.org/MixedModels.jl/dev/"><code>MixedModels.jl</code></a>. The syntax is done by using the <code>@formula</code> macro and then specifying the dependent variable followed by a tilde <code>~</code> then the independent variables separated by a plus sign <code>+</code>.</p><p>Example: <code>@formula(y ~ x1 + x2 + x3)</code>.</p><p>Moderations/interactions can be specified with the asterisk sign <code>*</code>, e.g. <code>x1 * x2</code>. This will be expanded to <code>x1 + x2 + x1:x2</code>, which, following the principle of hierarchy, the main effects must also be added along with the interaction effects. Here <code>x1:x2</code> means that the values of <code>x1</code> will be multiplied (interacted) with the values of <code>x2</code>.</p><p>Random-effects (a.k.a. group-level effects) can be specified with the <code>(term | group)</code> inside the <code>@formula</code>, where <code>term</code> is the independent variable and <code>group</code> is the <strong>categorical</strong> representation (i.e., either a column of <code>String</code>s or a <code>CategoricalArray</code> in <code>data</code>). You can specify a random-intercept with <code>(1 | group)</code>.</p><p>Example: <code>@formula(y ~ (1 | group) + x1)</code>.</p><p><strong>Notice: random-effects are currently only implemented for a single group-level intercept. Future versions of <code>TuringGLM.jl</code> will support slope random-effects and multiple group-level effets.</strong></p><p><strong><code>data</code></strong></p><p><code>data</code> can be any <code>Tables.jl</code>-compatible data interface. The most popular ones are <code>DataFrame</code>s and <code>NamedTuple</code>s.</p><p><strong><code>model</code></strong></p><p><code>model</code> represents the likelihood function which you want to condition your data on. Currently, <code>TuringGLM.jl</code> supports:</p><ul><li><code>Gaussian()</code> (the default if not specified): linear regression</li><li><code>Student()</code>: robust linear regression</li><li><code>Logistic()</code>: logistic regression</li><li><code>Pois()</code>: Poisson count data regression</li><li><code>NegBin()</code>: negative binomial robust count data regression</li></ul><p><strong><code>priors</code></strong></p><p><code>TuringGLM.jl</code> comes with state-of-the-art default priors, based on the literature and the Stan community. By default, <code>turing_model</code> will use <code>DefaultPrior</code>. But you can specify your own with <code>priors=CustomPrior(predictors, intercept, auxiliary)</code>. All models take a <code>predictors</code> and <code>intercept</code> priors.</p><p>In robust models, e.g. Linear Regression with Student-t likelihood or Count Regression with Negative Binomial likelihood, often there is an extra auxiliary parameter that is needed to parametrize to model to overcome under- or over-dispersion. If you are specifying a custom prior for one of these type of models, then you should also specify a prior for the auxiliary parameter.</p><p>Non-robust models do not need an auxiliary parameter and you can pass <code>nothing</code> as the auxiliary argument.</p><p>Example for a non-robust model: <code>@formula(y, ...), data; priors=CustomPrior(Normal(0, 2.5), Normal(10, 5), nothing)</code></p><p>Example for a robust model: <code>@formula(y, ...), data; priors=CustomPrior(Normal(0, 2.5), Normal(10, 5), Exponential(1))</code></p><p><strong><code>standardize</code></strong></p><p>Whether <code>true</code> or <code>false</code> to standardize your data to mean 0 and standard deviation 1 before inference. Some science fields prefer to analyze and report effects in terms of standard devations. Also, whenever measurement scales differs, it is often suggested to standardize the effects for better comparison. By default, <code>turing_model</code> sets <code>standardize=false</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TuringLang/TuringGLM.jl/blob/7ead39d2795dab9e01b8c2881783c4228ae25ec5/src/turing_model.jl#L1-L79">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../tutorials/custom_priors/">« Custom Priors</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.10 on <span class="colophon-date" title="Tuesday 11 January 2022 20:20">Tuesday 11 January 2022</span>. Using Julia version 1.6.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
